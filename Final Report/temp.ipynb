{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extension that allows us to compile CUDA code in python notebooks\n",
    "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc4jupyter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cuda_group_save -g \"knn\" -n \"main.cu\"\n",
    "\n",
    "// Required header files / 所需的头文件\n",
    "#include <iostream>     // For input/output operations / 用于输入输出操作\n",
    "#include <fstream>      // For file operations / 用于文件操作\n",
    "#include <vector>       // For vector container / 用于向量容器\n",
    "#include <string>       // For string operations / 用于字符串操作\n",
    "#include <cstring>      // For C-style string operations / 用于C风格字符串操作\n",
    "#include <algorithm>    // For algorithms like max_element / 用于算法如max_element\n",
    "#include <cuda_runtime.h> // For CUDA operations / 用于CUDA操作\n",
    "#include <cfloat>\n",
    "\n",
    "// Constants definition / 常量定义\n",
    "#define THREADS 256        // Number of threads per block / 每个块的线程数\n",
    "#define IMAGESIZE 784      // Image size (28x28 = 784 pixels) / 图像大小 (28x28 = 784像素)\n",
    "#define TILE_WIDTH 32\n",
    "#define SHARED_MEM_SIZE (TILE_WIDTH * IMAGESIZE)\n",
    "\n",
    "// Function to handle big-endian to little-endian conversion\n",
    "// 处理大端序转小端序的函数\n",
    "uint32_t swap32(uint32_t val) {\n",
    "    val = ((val << 8) & 0xFF00FF00) | ((val >> 8) & 0xFF00FF);\n",
    "    return (val << 16) | (val >> 16);\n",
    "}\n",
    "\n",
    "// structure to store training/testing samples\n",
    "// 存储训练/测试样本的结构体\n",
    "struct TrainingSample {\n",
    "    int label;                  // The digit (0-9) / 数字标签 (0-9)\n",
    "    float image[IMAGESIZE];     // Normalized pixel values / 归一化的像素值\n",
    "};\n",
    "\n",
    "__global__ void bitonicSortStep(float* d_distances, int* d_labels, int j, int k, int num_samples) {\n",
    "    // 使用共享内存来减少全局内存访问\n",
    "    __shared__ float s_distances[1024];  // 设置为合适的大小\n",
    "    __shared__ int s_labels[1024];\n",
    "    \n",
    "    const unsigned int tid = threadIdx.x;\n",
    "    const unsigned int bid = blockIdx.x;\n",
    "    const unsigned int gid = bid * blockDim.x + tid;\n",
    "    const unsigned int gridSize = gridDim.x * blockDim.x;\n",
    "    \n",
    "    // 每个线程块处理多个元素\n",
    "    for (unsigned int i = gid; i < num_samples; i += gridSize) {\n",
    "        s_distances[tid] = d_distances[i];\n",
    "        s_labels[tid] = d_labels[i];\n",
    "        __syncthreads();\n",
    "        \n",
    "        unsigned int ixj = i ^ j;\n",
    "        \n",
    "        if (ixj > i && ixj < num_samples) {\n",
    "            float dist_i = s_distances[tid];\n",
    "            float dist_ixj = d_distances[ixj];\n",
    "            int label_i = s_labels[tid];\n",
    "            int label_ixj = d_labels[ixj];\n",
    "            \n",
    "            bool swap = ((i & k) == 0) ? (dist_i > dist_ixj) : (dist_i < dist_ixj);\n",
    "            \n",
    "            if (swap) {\n",
    "                s_distances[tid] = dist_ixj;\n",
    "                s_labels[tid] = label_ixj;\n",
    "                d_distances[ixj] = dist_i;\n",
    "                d_labels[ixj] = label_i;\n",
    "            }\n",
    "        }\n",
    "        __syncthreads();\n",
    "        \n",
    "        d_distances[i] = s_distances[tid];\n",
    "        d_labels[i] = s_labels[tid];\n",
    "    }\n",
    "}\n",
    "\n",
    "void bitonicSort(float* d_distances, int* d_labels, int num_samples) {\n",
    "    // 计算最近的2的幂\n",
    "    int pow2_size = 1;\n",
    "    while (pow2_size < num_samples) pow2_size <<= 1;\n",
    "    int padded_size = pow2_size;\n",
    "    \n",
    "    // 一次性初始化填充数据\n",
    "    if (padded_size > num_samples) {\n",
    "        const float max_distance = FLT_MAX;\n",
    "        const int max_label = -1;\n",
    "        \n",
    "        // 分配并初始化填充数据\n",
    "        float* h_pad_distances = new float[padded_size - num_samples];\n",
    "        int* h_pad_labels = new int[padded_size - num_samples];\n",
    "        \n",
    "        for (int i = 0; i < padded_size - num_samples; ++i) {\n",
    "            h_pad_distances[i] = max_distance;\n",
    "            h_pad_labels[i] = max_label;\n",
    "        }\n",
    "        \n",
    "        cudaMemcpy(d_distances + num_samples, h_pad_distances,\n",
    "                  (padded_size - num_samples) * sizeof(float), cudaMemcpyHostToDevice);\n",
    "        cudaMemcpy(d_labels + num_samples, h_pad_labels,\n",
    "                  (padded_size - num_samples) * sizeof(int), cudaMemcpyHostToDevice);\n",
    "                  \n",
    "        delete[] h_pad_distances;\n",
    "        delete[] h_pad_labels;\n",
    "    }\n",
    "    \n",
    "    // 优化的网格配置\n",
    "    const int threadsPerBlock = 256;\n",
    "    const int numBlocks = (padded_size + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "    // 使用循环展开来减少循环开销\n",
    "    #pragma unroll 4\n",
    "    for (int k = 2; k <= pow2_size; k <<= 1) {\n",
    "        #pragma unroll 4\n",
    "        for (int j = k >> 1; j > 0; j >>= 1) {\n",
    "            bitonicSortStep<<<numBlocks, threadsPerBlock>>>(\n",
    "                d_distances, d_labels, j, k, padded_size);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void computeEuclideanDistances(float* d_images, float* d_testImage,\n",
    "                                          float* d_distances, int* d_labels,\n",
    "                                          int* d_train_labels, int num_samples) {\n",
    "    __shared__ float shared_test[IMAGESIZE];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int bid = blockIdx.x;\n",
    "    int idx = bid * blockDim.x + tid;\n",
    "    \n",
    "    // 高效加载测试图像到共享内存\n",
    "    #pragma unroll\n",
    "    for (int i = 0; i < IMAGESIZE; i += blockDim.x) {\n",
    "        if (i + tid < IMAGESIZE) {\n",
    "            shared_test[i + tid] = d_testImage[i + tid];\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    if (idx < num_samples) {\n",
    "        float sum = 0.0f;\n",
    "        \n",
    "        // 使用更高效的计算方式\n",
    "        #pragma unroll 32\n",
    "        for (int i = 0; i < IMAGESIZE; ++i) {\n",
    "            float diff = d_images[idx * IMAGESIZE + i] - shared_test[i];\n",
    "            sum += diff * diff;\n",
    "        }\n",
    "        \n",
    "        d_distances[idx] = sqrtf(sum);\n",
    "        d_labels[idx] = d_train_labels[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// function to load MNIST dataset in IDX format\n",
    "// 加载IDX格式MNIST数据集的函数\n",
    "bool loadMNISTImages(const std::string& image_path, const std::string& label_path,\n",
    "                    std::vector<TrainingSample>& samples) {\n",
    "    // Open image file / 打开图像文件\n",
    "    std::ifstream image_file(image_path, std::ios::binary);\n",
    "    if (!image_file) {\n",
    "        std::cerr << \"Cannot open image file: \" << image_path << std::endl;\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    // Open label file / 打开标签文件\n",
    "    std::ifstream label_file(label_path, std::ios::binary);\n",
    "    if (!label_file) {\n",
    "        std::cerr << \"Cannot open label file: \" << label_path << std::endl;\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    // Read image file header / 读取图像文件头\n",
    "    uint32_t magic, num_items, num_rows, num_cols;\n",
    "    image_file.read(reinterpret_cast<char*>(&magic), sizeof(magic));\n",
    "    image_file.read(reinterpret_cast<char*>(&num_items), sizeof(num_items));\n",
    "    image_file.read(reinterpret_cast<char*>(&num_rows), sizeof(num_rows));\n",
    "    image_file.read(reinterpret_cast<char*>(&num_cols), sizeof(num_cols));\n",
    "\n",
    "    // Convert from big-endian to host endian / 从大端序转换为主机字节序\n",
    "    magic = swap32(magic);\n",
    "    num_items = swap32(num_items);\n",
    "    num_rows = swap32(num_rows);\n",
    "    num_cols = swap32(num_cols);\n",
    "\n",
    "    // Verify image file format / 验证图像文件格式\n",
    "    if (magic != 0x803) {\n",
    "        std::cerr << \"Invalid image file format\" << std::endl;\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    // Read label file header / 读取标签文件头\n",
    "    uint32_t label_magic, num_labels;\n",
    "    label_file.read(reinterpret_cast<char*>(&label_magic), sizeof(label_magic));\n",
    "    label_file.read(reinterpret_cast<char*>(&num_labels), sizeof(num_labels));\n",
    "\n",
    "    // Convert label file header / 转换标签文件头\n",
    "    label_magic = swap32(label_magic);\n",
    "    num_labels = swap32(num_labels);\n",
    "\n",
    "    // Verify label file format / 验证标签文件格式\n",
    "    if (label_magic != 0x801) {\n",
    "        std::cerr << \"Invalid label file format\" << std::endl;\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    // Check consistency between images and labels / 检查图像和标签数量是否一致\n",
    "    if (num_items != num_labels) {\n",
    "        std::cerr << \"Number of images doesn't match number of labels\" << std::endl;\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    // Prepare storage / 准备存储空间\n",
    "    samples.resize(num_items);\n",
    "    std::vector<unsigned char> pixels(num_rows * num_cols);\n",
    "\n",
    "    // Read and process each sample / 读取并处理每个样本\n",
    "    for (uint32_t i = 0; i < num_items; ++i) {\n",
    "        // Read label / 读取标签\n",
    "        unsigned char label;\n",
    "        label_file.read(reinterpret_cast<char*>(&label), 1);\n",
    "        samples[i].label = static_cast<int>(label);\n",
    "\n",
    "        // Read image / 读取图像\n",
    "        image_file.read(reinterpret_cast<char*>(pixels.data()), pixels.size());\n",
    "\n",
    "        // Normalize pixel values to [0,1] / 将像素值归一化到[0,1]范围\n",
    "        for (size_t j = 0; j < pixels.size(); ++j) {\n",
    "            samples[i].image[j] = static_cast<float>(pixels[j]) / 255.0f;\n",
    "        }\n",
    "\n",
    "        // Show progress / 显示进度\n",
    "        if (i % 1000 == 0) {\n",
    "            std::cout << \"\\rLoading data: \" << (i * 100.0f / num_items) << \"%\" << std::flush;\n",
    "        }\n",
    "    }\n",
    "    std::cout << \"\\rLoading data: 100%\" << std::endl;\n",
    "\n",
    "    return true;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Timing events\n",
    "    cudaEvent_t total_start, total_stop;\n",
    "    cudaEventCreate(&total_start);\n",
    "    cudaEventCreate(&total_stop);\n",
    "    cudaEventRecord(total_start);\n",
    "\n",
    "    cudaEvent_t load_start, load_stop;\n",
    "    cudaEventCreate(&load_start);\n",
    "    cudaEventCreate(&load_stop);\n",
    "    cudaEventRecord(load_start);\n",
    "\n",
    "    // Load data\n",
    "    std::vector<TrainingSample> train_samples;\n",
    "    std::vector<TrainingSample> test_samples;\n",
    "\n",
    "    if (!loadMNISTImages(\"/content/drive/MyDrive/GPU_knn/train_mnist/MNIST/raw/train-images-idx3-ubyte\",\n",
    "                        \"/content/drive/MyDrive/GPU_knn/train_mnist/MNIST/raw/train-labels-idx1-ubyte\",\n",
    "                        train_samples)) {\n",
    "        return -1;\n",
    "    }\n",
    "    if (!loadMNISTImages(\"/content/drive/MyDrive/GPU_knn/test_mnist/MNIST/raw/t10k-images-idx3-ubyte\",\n",
    "                        \"/content/drive/MyDrive/GPU_knn/test_mnist/MNIST/raw/t10k-labels-idx1-ubyte\",\n",
    "                        test_samples)) {\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    cudaEventRecord(load_stop);\n",
    "    cudaEventSynchronize(load_stop);\n",
    "    float load_time;\n",
    "    cudaEventElapsedTime(&load_time, load_start, load_stop);\n",
    "    \n",
    "    std::cout << \"Successfully loaded \" << train_samples.size() << \" training samples.\" << std::endl;\n",
    "    std::cout << \"Successfully loaded \" << test_samples.size() << \" testing samples.\" << std::endl;\n",
    "    std::cout << \"Data loading time: \" << load_time/1000 << \" seconds\" << std::endl;\n",
    "\n",
    "    // GPU transfer timing\n",
    "    cudaEvent_t transfer_start, transfer_stop;\n",
    "    cudaEventCreate(&transfer_start);\n",
    "    cudaEventCreate(&transfer_stop);\n",
    "    cudaEventRecord(transfer_start);\n",
    "\n",
    "    int num_trainsamples = train_samples.size();\n",
    "    int num_testsamples = test_samples.size();\n",
    "\n",
    "    // Allocate host memory for training data\n",
    "    float* h_train_images = new float[num_trainsamples * IMAGESIZE];\n",
    "    int* h_train_labels = new int[num_trainsamples];\n",
    "\n",
    "    for (int i = 0; i < num_trainsamples; ++i) {\n",
    "        h_train_labels[i] = train_samples[i].label;\n",
    "        std::memcpy(&h_train_images[i * IMAGESIZE], train_samples[i].image, sizeof(float) * IMAGESIZE);\n",
    "    }\n",
    "\n",
    "    // Pre-allocate all GPU memory we'll need\n",
    "    float* d_train_images;\n",
    "    int* d_train_labels;\n",
    "    float* d_test_image;\n",
    "    float* d_distances;\n",
    "    int* d_sort_labels;\n",
    "    \n",
    "    // Calculate padded size once\n",
    "    int pow2_size = 1;\n",
    "    while (pow2_size < num_trainsamples) pow2_size <<= 1;\n",
    "    int padded_size = pow2_size;\n",
    "\n",
    "    // Allocate all GPU memory at once\n",
    "    cudaMalloc(&d_train_images, num_trainsamples * IMAGESIZE * sizeof(float));\n",
    "    cudaMalloc(&d_train_labels, num_trainsamples * sizeof(int));\n",
    "    cudaMalloc(&d_test_image, IMAGESIZE * sizeof(float));\n",
    "    cudaMalloc(&d_distances, padded_size * sizeof(float));\n",
    "    cudaMalloc(&d_sort_labels, padded_size * sizeof(int));\n",
    "\n",
    "    // Copy training data to GPU\n",
    "    cudaMemcpy(d_train_images, h_train_images, num_trainsamples * IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_train_labels, h_train_labels, num_trainsamples * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Pre-allocate host memory for results\n",
    "    float* h_distances = new float[10];  // for k=10\n",
    "    int* h_labels = new int[10];\n",
    "\n",
    "    // Initialize padding arrays once\n",
    "    if (padded_size > num_trainsamples) {\n",
    "        float* h_pad_distances = new float[padded_size - num_trainsamples];\n",
    "        int* h_pad_labels = new int[padded_size - num_trainsamples];\n",
    "        for (int i = 0; i < padded_size - num_trainsamples; ++i) {\n",
    "            h_pad_distances[i] = FLT_MAX;\n",
    "            h_pad_labels[i] = -1;\n",
    "        }\n",
    "        cudaMemcpy(d_distances + num_trainsamples, h_pad_distances, \n",
    "                  (padded_size - num_trainsamples) * sizeof(float), cudaMemcpyHostToDevice);\n",
    "        cudaMemcpy(d_sort_labels + num_trainsamples, h_pad_labels, \n",
    "                  (padded_size - num_trainsamples) * sizeof(int), cudaMemcpyHostToDevice);\n",
    "        delete[] h_pad_distances;\n",
    "        delete[] h_pad_labels;\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(transfer_stop);\n",
    "    cudaEventSynchronize(transfer_stop);\n",
    "    float transfer_time;\n",
    "    cudaEventElapsedTime(&transfer_time, transfer_start, transfer_stop);\n",
    "    std::cout << \"GPU data transfer time: \" << transfer_time/1000 << \" seconds\" << std::endl;\n",
    "\n",
    "    // Start prediction timing\n",
    "    cudaEvent_t predict_start, predict_stop;\n",
    "    cudaEventCreate(&predict_start);\n",
    "    cudaEventCreate(&predict_stop);\n",
    "    cudaEventRecord(predict_start);\n",
    "\n",
    "    // KNN parameters\n",
    "    int k = 10;\n",
    "    int correct_predictions = 0;\n",
    "\n",
    "    // Process each test sample\n",
    "    for (int t = 0; t < num_testsamples; ++t) {\n",
    "        if (t % 100 == 0) {\n",
    "            std::cout << \"\\rProcessing test samples: \" << (t * 100.0f / num_testsamples) << \"%\" << std::flush;\n",
    "        }\n",
    "\n",
    "        int test_label = test_samples[t].label;\n",
    "\n",
    "        // Copy test image to GPU (reuse pre-allocated memory)\n",
    "        cudaMemcpy(d_test_image, test_samples[t].image, IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "        int threadsPerBlock = TILE_WIDTH;\n",
    "        int blocksPerGrid = (num_trainsamples + threadsPerBlock - 1) / threadsPerBlock;\n",
    "        computeEuclideanDistances<<<blocksPerGrid, threadsPerBlock>>>(\n",
    "            d_train_images, d_test_image, d_distances, d_sort_labels, d_train_labels, num_trainsamples\n",
    "        );;\n",
    "\n",
    "        // Sort distances\n",
    "        bitonicSort(d_distances, d_sort_labels, num_trainsamples);\n",
    "\n",
    "        // Get top k results\n",
    "        cudaMemcpy(h_distances, d_distances, k * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "        cudaMemcpy(h_labels, d_sort_labels, k * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "        // Count label frequencies\n",
    "        std::vector<int> labelCount(10, 0);\n",
    "        for (int i = 0; i < k; ++i) {\n",
    "            labelCount[h_labels[i]]++;\n",
    "        }\n",
    "\n",
    "        int predictedLabel = std::distance(labelCount.begin(),\n",
    "                                         std::max_element(labelCount.begin(), labelCount.end()));\n",
    "\n",
    "        if (predictedLabel == test_label) {\n",
    "            correct_predictions++;\n",
    "        }\n",
    "\n",
    "        if (t % 1000 == 0) {\n",
    "            std::cout << \"\\nTest Sample \" << t << \": Actual = \" << test_label\n",
    "                     << \", Predicted = \" << predictedLabel << std::endl;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Record prediction time\n",
    "    cudaEventRecord(predict_stop);\n",
    "    cudaEventSynchronize(predict_stop);\n",
    "    float predict_time;\n",
    "    cudaEventElapsedTime(&predict_time, predict_start, predict_stop);\n",
    "\n",
    "    // Record total time\n",
    "    cudaEventRecord(total_stop);\n",
    "    cudaEventSynchronize(total_stop);\n",
    "    float total_time;\n",
    "    cudaEventElapsedTime(&total_time, total_start, total_stop);\n",
    "\n",
    "    // Calculate and display results\n",
    "    float accuracy = (float)correct_predictions / num_testsamples * 100.0f;\n",
    "    \n",
    "    std::cout << \"\\rProcessing test samples: 100%\" << std::endl;\n",
    "    std::cout << \"\\nFinal Results:\" << std::endl;\n",
    "    std::cout << \"Total test samples: \" << num_testsamples << std::endl;\n",
    "    std::cout << \"Correct predictions: \" << correct_predictions << std::endl;\n",
    "    \n",
    "    std::cout << \"\\nTiming Information:\" << std::endl;\n",
    "    std::cout << \"Data loading time: \" << load_time/1000 << \" seconds\" << std::endl;\n",
    "    std::cout << \"GPU data transfer time: \" << transfer_time/1000 << \" seconds\" << std::endl;\n",
    "    std::cout << \"Prediction time: \" << predict_time/1000 << \" seconds\" << std::endl;\n",
    "    std::cout << \"Total execution time: \" << total_time/1000 << \" seconds\" << std::endl;\n",
    "    std::cout << \"Average time per prediction: \" << predict_time/(1000*num_testsamples) << \" seconds\" << std::endl;\n",
    "    std::cout << \"Accuracy: \" << accuracy << \"%\" << std::endl;\n",
    "\n",
    "    // Cleanup\n",
    "    cudaEventDestroy(total_start);\n",
    "    cudaEventDestroy(total_stop);\n",
    "    cudaEventDestroy(load_start);\n",
    "    cudaEventDestroy(load_stop);\n",
    "    cudaEventDestroy(transfer_start);\n",
    "    cudaEventDestroy(transfer_stop);\n",
    "    cudaEventDestroy(predict_start);\n",
    "    cudaEventDestroy(predict_stop);\n",
    "\n",
    "    // Free all allocated memory at once\n",
    "    delete[] h_train_images;\n",
    "    delete[] h_train_labels;\n",
    "    delete[] h_distances;\n",
    "    delete[] h_labels;\n",
    "    cudaFree(d_train_images);\n",
    "    cudaFree(d_train_labels);\n",
    "    cudaFree(d_test_image);\n",
    "    cudaFree(d_distances);\n",
    "    cudaFree(d_sort_labels);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_group_run --group \"knn\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
