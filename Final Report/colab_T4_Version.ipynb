{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sg86ybxfYCM",
        "outputId": "8ddca592-655e-4a98-a977-b5408e04aa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9cgjep6z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9cgjep6z\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "# Load the extension that allows us to compile CUDA code in python notebooks\n",
        "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUFIYVolT5O"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ca_dytlrnY",
        "outputId": "dd6b9f4e-9082-45ff-ddc6-a8914d9c166f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST dataset downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import os\n",
        "\n",
        "def download_mnist_dataset():\n",
        "    # 创建目录\n",
        "    os.makedirs(\"train_mnist/MNIST/raw\", exist_ok=True)\n",
        "    os.makedirs(\"test_mnist/MNIST/raw\", exist_ok=True)\n",
        "\n",
        "    # 下载训练数据\n",
        "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "    print(\"MNIST dataset downloaded successfully.\")\n",
        "\n",
        "# 调用函数下载数据集\n",
        "download_mnist_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-X3xtiKKRV6i",
        "outputId": "c66599b7-5c22-440b-d1dc-f0d03f7aa4a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'''\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yg7P0ezLfcos"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"knn\" -n \"main.cu\"\n",
        "\n",
        "// Required header files / 所需的头文件\n",
        "#include <iostream>     // For input/output operations / 用于输入输出操作\n",
        "#include <fstream>      // For file operations / 用于文件操作\n",
        "#include <vector>       // For vector container / 用于向量容器\n",
        "#include <string>       // For string operations / 用于字符串操作\n",
        "#include <cstring>      // For C-style string operations / 用于C风格字符串操作\n",
        "#include <algorithm>    // For algorithms like max_element / 用于算法如max_element\n",
        "#include <cuda_runtime.h> // For CUDA operations / 用于CUDA操作\n",
        "#include <cfloat>\n",
        "#include <chrono>    // For timing execution / 用于执行时间计算\n",
        "\n",
        "// Constants definition / 常量定义\n",
        "#define THREADS 256        // Number of threads per block / 每个块的线程数\n",
        "#define IMAGESIZE 784      // Image size (28x28 = 784 pixels) / 图像大小 (28x28 = 784像素)\n",
        "\n",
        "// Function to handle big-endian to little-endian conversion\n",
        "// 处理大端序转小端序的函数\n",
        "uint32_t swap32(uint32_t val) {\n",
        "    val = ((val << 8) & 0xFF00FF00) | ((val >> 8) & 0xFF00FF);\n",
        "    return (val << 16) | (val >> 16);\n",
        "}\n",
        "\n",
        "// structure to store training/testing samples\n",
        "// 存储训练/测试样本的结构体\n",
        "struct TrainingSample {\n",
        "    int label;                  // The digit (0-9) / 数字标签 (0-9)\n",
        "    float image[IMAGESIZE];     // Normalized pixel values / 归一化的像素值\n",
        "};\n",
        "\n",
        "struct KernelTiming {\n",
        "    float data_transfer;\n",
        "    float distance_calc;\n",
        "    float sorting;\n",
        "    int num_samples;\n",
        "} timing = {0.0f, 0.0f, 0.0f, 0};\n",
        "\n",
        "__global__ void bitonicSortStep(float* d_distances, int* d_labels, int j, int k, int num_samples) {\n",
        "    unsigned int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (i >= num_samples) return;\n",
        "\n",
        "    unsigned int ixj = i ^ j;\n",
        "\n",
        "    if (ixj > i && ixj < num_samples) {\n",
        "        // determine the sorting direction\n",
        "        if ((i & k) == 0) {\n",
        "            // sort in ascending order\n",
        "            if (d_distances[i] > d_distances[ixj]) {\n",
        "                // swap distances\n",
        "                float temp_dist = d_distances[i];\n",
        "                d_distances[i] = d_distances[ixj];\n",
        "                d_distances[ixj] = temp_dist;\n",
        "\n",
        "                // swap corresponding labels\n",
        "                int temp_label = d_labels[i];\n",
        "                d_labels[i] = d_labels[ixj];\n",
        "                d_labels[ixj] = temp_label;\n",
        "            }\n",
        "        } else {\n",
        "            // sort in descending order\n",
        "            if (d_distances[i] < d_distances[ixj]) {\n",
        "                // swap distances\n",
        "                float temp_dist = d_distances[i];\n",
        "                d_distances[i] = d_distances[ixj];\n",
        "                d_distances[ixj] = temp_dist;\n",
        "\n",
        "                // swap corresponding labels\n",
        "                int temp_label = d_labels[i];\n",
        "                d_labels[i] = d_labels[ixj];\n",
        "                d_labels[ixj] = temp_label;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void bitonicSort(float* d_distances, int* d_labels, int num_samples, cudaStream_t stream) {\n",
        "    // Calculate the next power of two\n",
        "    int pow2_size = 1;\n",
        "    while (pow2_size < num_samples) pow2_size <<= 1;\n",
        "\n",
        "    // Pad the distances and labels with maximum values\n",
        "    int padded_size = pow2_size;\n",
        "    if (padded_size > num_samples) {\n",
        "        float max_distance = FLT_MAX;\n",
        "        int max_label = -1; // Use an invalid label for padding\n",
        "\n",
        "        // Create temporary arrays for padding\n",
        "        float* h_pad_distances;\n",
        "        int* h_pad_labels;\n",
        "        cudaMallocHost(&h_pad_distances, (padded_size - num_samples) * sizeof(float));\n",
        "        cudaMallocHost(&h_pad_labels, (padded_size - num_samples) * sizeof(int));\n",
        "        \n",
        "        for (int i = 0; i < padded_size - num_samples; ++i) {\n",
        "            h_pad_distances[i] = max_distance;\n",
        "            h_pad_labels[i] = max_label;\n",
        "        }\n",
        "\n",
        "        // Copy padding data to device asynchronously\n",
        "        cudaMemcpyAsync(d_distances + num_samples, \n",
        "                       h_pad_distances, \n",
        "                       (padded_size - num_samples) * sizeof(float), \n",
        "                       cudaMemcpyHostToDevice,\n",
        "                       stream);\n",
        "        cudaMemcpyAsync(d_labels + num_samples, \n",
        "                       h_pad_labels, \n",
        "                       (padded_size - num_samples) * sizeof(int), \n",
        "                       cudaMemcpyHostToDevice,\n",
        "                       stream);\n",
        "\n",
        "        // Free temporary host arrays\n",
        "        cudaFreeHost(h_pad_distances);\n",
        "        cudaFreeHost(h_pad_labels);\n",
        "    }\n",
        "\n",
        "    // Set up grid and block dimensions\n",
        "    dim3 block(THREADS);\n",
        "    dim3 grid((padded_size + block.x - 1) / block.x);\n",
        "\n",
        "    // Main sorting loops\n",
        "    for (int k = 2; k <= pow2_size; k <<= 1) {\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {\n",
        "            bitonicSortStep<<<grid, block, 0, stream>>>(\n",
        "                d_distances, d_labels, j, k, padded_size\n",
        "            );\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// 1. 优化的向量化距离计算核函数\n",
        "__global__ void computeEuclideanDistances(float* d_images, float* d_testImage,\n",
        "                                        float* d_distances, int* d_labels,\n",
        "                                        int* d_train_labels, int num_samples) {\n",
        "    extern __shared__ float shared_mem[];\n",
        "    float* shared_test = shared_mem;\n",
        "    \n",
        "    int tid = threadIdx.x;\n",
        "    int bid = blockIdx.x;\n",
        "    int idx = bid * blockDim.x + tid;\n",
        "    \n",
        "    // 使用协作加载来提高内存访问效率\n",
        "    for (int i = tid; i < IMAGESIZE; i += blockDim.x) {\n",
        "        shared_test[i] = d_testImage[i];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    \n",
        "    if (idx < num_samples) {\n",
        "        float sum = 0.0f;\n",
        "        \n",
        "        // 使用循环展开和向量加载来优化计算\n",
        "        float4* img_vec = (float4*)(&d_images[idx * IMAGESIZE]);\n",
        "        float4* test_vec = (float4*)shared_test;\n",
        "        \n",
        "        #pragma unroll 16\n",
        "        for (int i = 0; i < IMAGESIZE/4; i++) {\n",
        "            float4 diff;\n",
        "            float4 img = img_vec[i];\n",
        "            float4 test = test_vec[i];\n",
        "            \n",
        "            diff.x = img.x - test.x;\n",
        "            diff.y = img.y - test.y;\n",
        "            diff.z = img.z - test.z;\n",
        "            diff.w = img.w - test.w;\n",
        "            \n",
        "            sum += diff.x * diff.x + diff.y * diff.y + \n",
        "                   diff.z * diff.z + diff.w * diff.w;\n",
        "        }\n",
        "        \n",
        "        // Handle remaining elements\n",
        "        for (int i = (IMAGESIZE/4)*4; i < IMAGESIZE; i++) {\n",
        "            float diff = d_images[idx * IMAGESIZE + i] - shared_test[i];\n",
        "            sum += diff * diff;\n",
        "        }\n",
        "        \n",
        "        d_distances[idx] = sqrtf(sum);\n",
        "        d_labels[idx] = d_train_labels[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// function to load MNIST dataset in IDX format\n",
        "// 加载IDX格式MNIST数据集的函数\n",
        "bool loadMNISTImages(const std::string& image_path, const std::string& label_path,\n",
        "                    std::vector<TrainingSample>& samples) {\n",
        "    // Open image file / 打开图像文件\n",
        "    std::ifstream image_file(image_path, std::ios::binary);\n",
        "    if (!image_file) {\n",
        "        std::cerr << \"Cannot open image file: \" << image_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Open label file / 打开标签文件\n",
        "    std::ifstream label_file(label_path, std::ios::binary);\n",
        "    if (!label_file) {\n",
        "        std::cerr << \"Cannot open label file: \" << label_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Read image file header / 读取图像文件头\n",
        "    uint32_t magic, num_items, num_rows, num_cols;\n",
        "    image_file.read(reinterpret_cast<char*>(&magic), sizeof(magic));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_items), sizeof(num_items));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_rows), sizeof(num_rows));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_cols), sizeof(num_cols));\n",
        "\n",
        "    // Convert from big-endian to host endian / 从大端序转换为主机字节序\n",
        "    magic = swap32(magic);\n",
        "    num_items = swap32(num_items);\n",
        "    num_rows = swap32(num_rows);\n",
        "    num_cols = swap32(num_cols);\n",
        "\n",
        "    // Verify image file format / 验证图像文件格式\n",
        "    if (magic != 0x803) {\n",
        "        std::cerr << \"Invalid image file format\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Read label file header / 读取标签文件头\n",
        "    uint32_t label_magic, num_labels;\n",
        "    label_file.read(reinterpret_cast<char*>(&label_magic), sizeof(label_magic));\n",
        "    label_file.read(reinterpret_cast<char*>(&num_labels), sizeof(num_labels));\n",
        "\n",
        "    // Convert label file header / 转换标签文件头\n",
        "    label_magic = swap32(label_magic);\n",
        "    num_labels = swap32(num_labels);\n",
        "\n",
        "    // Verify label file format / 验证标签文件格式\n",
        "    if (label_magic != 0x801) {\n",
        "        std::cerr << \"Invalid label file format\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Check consistency between images and labels / 检查图像和标签数量是否一致\n",
        "    if (num_items != num_labels) {\n",
        "        std::cerr << \"Number of images doesn't match number of labels\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Prepare storage / 准备存储空间\n",
        "    samples.resize(num_items);\n",
        "    std::vector<unsigned char> pixels(num_rows * num_cols);\n",
        "\n",
        "    // Read and process each sample / 读取并处理每个样本\n",
        "    for (uint32_t i = 0; i < num_items; ++i) {\n",
        "        // Read label / 读取标签\n",
        "        unsigned char label;\n",
        "        label_file.read(reinterpret_cast<char*>(&label), 1);\n",
        "        samples[i].label = static_cast<int>(label);\n",
        "\n",
        "        // Read image / 读取图像\n",
        "        image_file.read(reinterpret_cast<char*>(pixels.data()), pixels.size());\n",
        "\n",
        "        // Normalize pixel values to [0,1] / 将像素值归一化到[0,1]范围\n",
        "        for (size_t j = 0; j < pixels.size(); ++j) {\n",
        "            samples[i].image[j] = static_cast<float>(pixels[j]) / 255.0f;\n",
        "        }\n",
        "\n",
        "        // Show progress / 显示进度\n",
        "        if (i % 1000 == 0) {\n",
        "            std::cout << \"\\rLoading data: \" << (i * 100.0f / num_items) << \"%\" << std::flush;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"\\rLoading data: 100%\" << std::endl;\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Timing structure for kernel breakdown\n",
        "    struct KernelTiming {\n",
        "        float data_transfer;\n",
        "        float distance_calc;\n",
        "        float sorting;\n",
        "        int num_samples;\n",
        "    } timing = {0.0f, 0.0f, 0.0f, 0};\n",
        "\n",
        "    // Start timing\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "    \n",
        "    // Load data\n",
        "    std::vector<TrainingSample> train_samples;\n",
        "    std::vector<TrainingSample> test_samples;\n",
        "\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/train-images-idx3-ubyte\",\n",
        "                        \"./data/MNIST/raw/train-labels-idx1-ubyte\",\n",
        "                        train_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "    std::cout << \"Successfully loaded \" << train_samples.size() << \" training samples.\" << std::endl;\n",
        "\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/t10k-images-idx3-ubyte\",\n",
        "                        \"./data/MNIST/raw/t10k-labels-idx1-ubyte\",\n",
        "                        test_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "    std::cout << \"Successfully loaded \" << test_samples.size() << \" testing samples.\" << std::endl;\n",
        "\n",
        "    int num_trainsamples = train_samples.size();\n",
        "    int num_testsamples = test_samples.size();\n",
        "\n",
        "    // Allocate page-locked memory for better transfer speed\n",
        "    float* h_train_images;\n",
        "    int* h_train_labels;\n",
        "    cudaMallocHost(&h_train_images, num_trainsamples * IMAGESIZE * sizeof(float));\n",
        "    cudaMallocHost(&h_train_labels, num_trainsamples * sizeof(int));\n",
        "\n",
        "    // Copy data to page-locked memory\n",
        "    for (int i = 0; i < num_trainsamples; ++i) {\n",
        "        h_train_labels[i] = train_samples[i].label;\n",
        "        std::memcpy(&h_train_images[i * IMAGESIZE], train_samples[i].image, sizeof(float) * IMAGESIZE);\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    float* d_train_images;\n",
        "    int* d_train_labels;\n",
        "    cudaMalloc(&d_train_images, num_trainsamples * IMAGESIZE * sizeof(float));\n",
        "    cudaMalloc(&d_train_labels, num_trainsamples * sizeof(int));\n",
        "\n",
        "    // Copy training data to GPU\n",
        "    cudaMemcpy(d_train_images, h_train_images, num_trainsamples * IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_train_labels, h_train_labels, num_trainsamples * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // KNN parameters\n",
        "    const int k = 10;\n",
        "    int correct_predictions = 0;\n",
        "\n",
        "    // Create CUDA streams for parallel processing\n",
        "    const int NUM_STREAMS = 4;\n",
        "    cudaStream_t streams[NUM_STREAMS];\n",
        "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
        "        cudaStreamCreate(&streams[i]);\n",
        "    }\n",
        "\n",
        "    // Allocate memory for each stream\n",
        "    float* d_test_images[NUM_STREAMS];\n",
        "    float* d_distances[NUM_STREAMS];\n",
        "    int* d_sort_labels[NUM_STREAMS];\n",
        "    float* h_distances[NUM_STREAMS];\n",
        "    int* h_labels[NUM_STREAMS];\n",
        "    \n",
        "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
        "        cudaMalloc(&d_test_images[i], IMAGESIZE * sizeof(float));\n",
        "        cudaMalloc(&d_distances[i], num_trainsamples * sizeof(float));\n",
        "        cudaMalloc(&d_sort_labels[i], num_trainsamples * sizeof(int));\n",
        "        cudaMallocHost(&h_distances[i], k * sizeof(float));\n",
        "        cudaMallocHost(&h_labels[i], k * sizeof(int));\n",
        "    }\n",
        "\n",
        "    // Configure kernel parameters\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (num_trainsamples + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    size_t shared_mem_size = IMAGESIZE * sizeof(float);\n",
        "\n",
        "    // Process test samples in batches using streams\n",
        "    for (int t = 0; t < num_testsamples; t += NUM_STREAMS) {\n",
        "        // Launch work on each stream\n",
        "        for (int s = 0; s < NUM_STREAMS && (t + s) < num_testsamples; s++) {\n",
        "            int current_sample = t + s;\n",
        "            \n",
        "            // Create timing events\n",
        "            cudaEvent_t start_transfer, stop_transfer;\n",
        "            cudaEvent_t start_distance, stop_distance;\n",
        "            cudaEvent_t start_sort, stop_sort;\n",
        "            \n",
        "            cudaEventCreate(&start_transfer);\n",
        "            cudaEventCreate(&stop_transfer);\n",
        "            cudaEventCreate(&start_distance);\n",
        "            cudaEventCreate(&stop_distance);\n",
        "            cudaEventCreate(&start_sort);\n",
        "            cudaEventCreate(&stop_sort);\n",
        "\n",
        "            // Time data transfer\n",
        "            cudaEventRecord(start_transfer, streams[s]);\n",
        "            cudaMemcpyAsync(d_test_images[s], \n",
        "                          test_samples[current_sample].image,\n",
        "                          IMAGESIZE * sizeof(float), \n",
        "                          cudaMemcpyHostToDevice,\n",
        "                          streams[s]);\n",
        "            cudaEventRecord(stop_transfer, streams[s]);\n",
        "\n",
        "            // Time distance calculation\n",
        "            cudaEventRecord(start_distance, streams[s]);\n",
        "            computeEuclideanDistances<<<blocksPerGrid, threadsPerBlock, shared_mem_size, streams[s]>>>(\n",
        "                d_train_images,\n",
        "                d_test_images[s],\n",
        "                d_distances[s],\n",
        "                d_sort_labels[s],\n",
        "                d_train_labels,\n",
        "                num_trainsamples\n",
        "            );\n",
        "            cudaEventRecord(stop_distance, streams[s]);\n",
        "\n",
        "            // Time sorting\n",
        "            cudaEventRecord(start_sort, streams[s]);\n",
        "            bitonicSort(d_distances[s], d_sort_labels[s], num_trainsamples, streams[s]);\n",
        "            cudaEventRecord(stop_sort, streams[s]);\n",
        "\n",
        "            cudaMemcpyAsync(h_distances[s], d_distances[s],\n",
        "                          k * sizeof(float), cudaMemcpyDeviceToHost,\n",
        "                          streams[s]);\n",
        "            cudaMemcpyAsync(h_labels[s], d_sort_labels[s],\n",
        "                          k * sizeof(int), cudaMemcpyDeviceToHost,\n",
        "                          streams[s]);\n",
        "\n",
        "            // Calculate timing for this iteration\n",
        "            float transfer_time, distance_time, sort_time;\n",
        "            cudaEventSynchronize(stop_transfer);\n",
        "            cudaEventSynchronize(stop_distance);\n",
        "            cudaEventSynchronize(stop_sort);\n",
        "            \n",
        "            cudaEventElapsedTime(&transfer_time, start_transfer, stop_transfer);\n",
        "            cudaEventElapsedTime(&distance_time, start_distance, stop_distance);\n",
        "            cudaEventElapsedTime(&sort_time, start_sort, stop_sort);\n",
        "\n",
        "            // Accumulate times\n",
        "            timing.data_transfer += transfer_time;\n",
        "            timing.distance_calc += distance_time;\n",
        "            timing.sorting += sort_time;\n",
        "            timing.num_samples++;\n",
        "\n",
        "            // Cleanup timing events\n",
        "            cudaEventDestroy(start_transfer);\n",
        "            cudaEventDestroy(stop_transfer);\n",
        "            cudaEventDestroy(start_distance);\n",
        "            cudaEventDestroy(stop_distance);\n",
        "            cudaEventDestroy(start_sort);\n",
        "            cudaEventDestroy(stop_sort);\n",
        "        }\n",
        "\n",
        "        // Process results for this batch\n",
        "        for (int s = 0; s < NUM_STREAMS && (t + s) < num_testsamples; s++) {\n",
        "            cudaStreamSynchronize(streams[s]);\n",
        "            \n",
        "            int current_sample = t + s;\n",
        "            int test_label = test_samples[current_sample].label;\n",
        "\n",
        "            std::vector<int> labelCount(10, 0);\n",
        "            for (int i = 0; i < k; ++i) {\n",
        "                if (h_labels[s][i] >= 0 && h_labels[s][i] < 10) {\n",
        "                    labelCount[h_labels[s][i]]++;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            int predictedLabel = std::distance(labelCount.begin(),\n",
        "                                            std::max_element(labelCount.begin(), labelCount.end()));\n",
        "\n",
        "            if (predictedLabel == test_label) {\n",
        "                correct_predictions++;\n",
        "            }\n",
        "\n",
        "            if (current_sample % 1000 == 0) {\n",
        "                float current_accuracy = (float)correct_predictions / (current_sample + 1) * 100.0f;\n",
        "                std::cout << \"\\rProcessing: \" << current_sample << \"/\" << num_testsamples\n",
        "                         << \" (Accuracy: \" << current_accuracy << \"%)\" << std::flush;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Calculate final results\n",
        "    float accuracy = (float)correct_predictions / num_testsamples * 100.0f;\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);\n",
        "\n",
        "    // Print all results\n",
        "    std::cout << \"\\n\\nFinal Results:\" << std::endl;\n",
        "    std::cout << \"Total test samples: \" << num_testsamples << std::endl;\n",
        "    std::cout << \"Correct predictions: \" << correct_predictions << std::endl;\n",
        "    std::cout << \"Accuracy: \" << accuracy << \"%\" << std::endl;\n",
        "\n",
        "    std::cout << \"\\nKernel Timing Breakdown:\" << std::endl;\n",
        "    std::cout << \"Average Data Transfer Time: \" << timing.data_transfer / timing.num_samples << \" ms\" << std::endl;\n",
        "    std::cout << \"Average Distance Calculation Time: \" << timing.distance_calc / timing.num_samples << \" ms\" << std::endl;\n",
        "    std::cout << \"Average Sorting Time: \" << timing.sorting / timing.num_samples << \" ms\" << std::endl;\n",
        "    std::cout << \"Total Data Transfer Time: \" << timing.data_transfer << \" ms\" << std::endl;\n",
        "    std::cout << \"Total Distance Calculation Time: \" << timing.distance_calc << \" ms\" << std::endl;\n",
        "    std::cout << \"Total Sorting Time: \" << timing.sorting << \" ms\" << std::endl;\n",
        "    \n",
        "    std::cout << \"\\nTotal execution time: \" << duration.count() / 1000.0 << \" seconds\" << std::endl;\n",
        "\n",
        "    // Cleanup\n",
        "    for (int i = 0; i < NUM_STREAMS; i++) {\n",
        "        cudaFree(d_test_images[i]);\n",
        "        cudaFree(d_distances[i]);\n",
        "        cudaFree(d_sort_labels[i]);\n",
        "        cudaFreeHost(h_distances[i]);\n",
        "        cudaFreeHost(h_labels[i]);\n",
        "        cudaStreamDestroy(streams[i]);\n",
        "    }\n",
        "\n",
        "    cudaFreeHost(h_train_images);\n",
        "    cudaFreeHost(h_train_labels);\n",
        "    cudaFree(d_train_images);\n",
        "    cudaFree(d_train_labels);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC7tWV0Mh1hr",
        "outputId": "75b1ff19-c5b9-4ddd-d505-fe0d01b6ddd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rLoading data: 0%\rLoading data: 1.66667%\rLoading data: 3.33333%\rLoading data: 5%\rLoading data: 6.66667%\rLoading data: 8.33333%\rLoading data: 10%\rLoading data: 11.6667%\rLoading data: 13.3333%\rLoading data: 15%\rLoading data: 16.6667%\rLoading data: 18.3333%\rLoading data: 20%\rLoading data: 21.6667%\rLoading data: 23.3333%\rLoading data: 25%\rLoading data: 26.6667%\rLoading data: 28.3333%\rLoading data: 30%\rLoading data: 31.6667%\rLoading data: 33.3333%\rLoading data: 35%\rLoading data: 36.6667%\rLoading data: 38.3333%\rLoading data: 40%\rLoading data: 41.6667%\rLoading data: 43.3333%\rLoading data: 45%\rLoading data: 46.6667%\rLoading data: 48.3333%\rLoading data: 50%\rLoading data: 51.6667%\rLoading data: 53.3333%\rLoading data: 55%\rLoading data: 56.6667%\rLoading data: 58.3333%\rLoading data: 60%\rLoading data: 61.6667%\rLoading data: 63.3333%\rLoading data: 65%\rLoading data: 66.6667%\rLoading data: 68.3333%\rLoading data: 70%\rLoading data: 71.6667%\rLoading data: 73.3333%\rLoading data: 75%\rLoading data: 76.6667%\rLoading data: 78.3333%\rLoading data: 80%\rLoading data: 81.6667%\rLoading data: 83.3333%\rLoading data: 85%\rLoading data: 86.6667%\rLoading data: 88.3333%\rLoading data: 90%\rLoading data: 91.6667%\rLoading data: 93.3333%\rLoading data: 95%\rLoading data: 96.6667%\rLoading data: 98.3333%\rLoading data: 100%\n",
            "\rLoading data: 0%\rLoading data: 10%\rLoading data: 20%\rLoading data: 30%\rLoading data: 40%\rLoading data: 50%\rLoading data: 60%\rLoading data: 70%\rLoading data: 80%\rLoading data: 90%\rLoading data: 100%\n",
            "Training samples: 10000\n",
            "Test samples: 1000\n",
            "Processed 0 test samples\n",
            "Processed 100 test samples\n",
            "Processed 200 test samples\n",
            "Processed 300 test samples\n",
            "Processed 400 test samples\n",
            "Processed 500 test samples\n",
            "Processed 600 test samples\n",
            "Processed 700 test samples\n",
            "Processed 800 test samples\n",
            "Processed 900 test samples\n",
            "Total test samples: 1000\n",
            "Correct predictions: 477\n",
            "Accuracy: 47.70%\n",
            "Total execution time: 0.8644 seconds\n",
            "Prediction time: 0.6952 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cuda_group_run --group \"knn\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
