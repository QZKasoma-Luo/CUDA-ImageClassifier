{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNW1rgAAmGGKOcLA85WcfeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QZKasoma-Luo/CUDA-ImageClassifier/blob/main/save_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTud2Jr6P3cT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import jit, cuda\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "\n",
        "\n",
        "data = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "m, n = data.shape\n",
        "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
        "\n",
        "data_dev = data[0:1000].T\n",
        "Y_dev = data_dev[0]\n",
        "X_dev = data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "data_train = data[1000:m].T\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "_,m_train = X_train.shape"
      ],
      "metadata": {
        "id": "wGktAnMaP_nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "\n",
        "# CUDA kernel\n",
        "@cuda.jit\n",
        "def matmul(A, B, C):\n",
        "    \"\"\"Perform matrix multiplication of C = A * B\n",
        "    \"\"\"\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < C.shape[0] and col < C.shape[1]:\n",
        "        tmp = 0.\n",
        "        for k in range(A.shape[1]):\n",
        "            tmp += A[row, k] * B[k, col]\n",
        "        C[row, col] = tmp\n",
        "\n",
        "# Host code\n",
        "\n",
        "# Initialize the data arrays\n",
        "def matmul_host(A: np.ndarray, B: np.ndarray, A_shape: tuple, B_shape: tuple):\n",
        "\n",
        "  # Copy the arrays to the device\n",
        "  A_global_mem = cuda.to_device(A)\n",
        "  B_global_mem = cuda.to_device(B)\n",
        "\n",
        "  # Allocate memory on the device for the result\n",
        "  C_global_mem = cuda.device_array((A_shape[0], B_shape[1]))\n",
        "\n",
        "  # Configure the blocks\n",
        "  threadsperblock = (32, 32)\n",
        "  blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n",
        "  blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n",
        "  blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "  # Start the kernel\n",
        "  matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
        "\n",
        "  # Copy the result back to the host\n",
        "  C = C_global_mem.copy_to_host()\n",
        "  return C\n",
        "\n",
        "A = np.array([[3,4,7],[1,2,3]])\n",
        "B = np.array([[2],[1],[1]])\n",
        "\n",
        "C = matmul_host(A, B, A.shape, B.shape)\n",
        "print(C)\n",
        "print(type(C))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLk-nhDTQPUL",
        "outputId": "462996e1-5613-4c2d-c8db-7868eb2b2151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.]\n",
            " [ 7.]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1, b1, W2, b2, X):\n",
        "    Z1 = matmul_host(W1, X, W1.shape, X.shape) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    Z2 = matmul_host(W2, A1, W2.shape, A1.shape) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    dW2 = 1 / m * matmul_host(dZ2, A1.T, dZ2.shape, A1.T.shape)\n",
        "    db2 = 1 / m * np.sum(dZ2)\n",
        "    dZ1 = matmul_host(W2.T, dZ2, W2.T.shape, dZ2.shape) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / m * matmul_host(dZ1, X.T, dZ1.shape, X.T.shape)\n",
        "    db1 = 1 / m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "PMclvxPiQRX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        # if i % 10 == 0:\n",
        "        #     print(\"Iteration: \", i)\n",
        "        #     predictions = get_predictions(A2)\n",
        "        #     print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "wAFdHQ86QUTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_s_gpu = time.time()\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)\n",
        "time_e_gpu = time.time()\n",
        "print(\"Time gggggggpu taken: \", time_e_gpu - time_s_gpu)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVKvB4TcQWRy",
        "outputId": "8002456c-091b-41c2-f4e2-cdfdcd48a8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "[4 1 1 ... 1 9 8] [1 2 2 ... 7 2 8]\n",
            "0.09885365853658537\n",
            "Iteration:  10\n",
            "[4 1 2 ... 1 9 8] [1 2 2 ... 7 2 8]\n",
            "0.20834146341463414\n",
            "Iteration:  20\n",
            "[1 1 2 ... 1 9 8] [1 2 2 ... 7 2 8]\n",
            "0.29665853658536584\n",
            "Iteration:  30\n",
            "[1 1 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.3635853658536585\n",
            "Iteration:  40\n",
            "[1 8 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.4277560975609756\n",
            "Iteration:  50\n",
            "[1 8 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.49034146341463414\n",
            "Iteration:  60\n",
            "[1 8 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.5425609756097561\n",
            "Iteration:  70\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.5883170731707317\n",
            "Iteration:  80\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.6216829268292683\n",
            "Iteration:  90\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.6476829268292683\n",
            "Iteration:  100\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.6694146341463415\n",
            "Iteration:  110\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.6865853658536586\n",
            "Iteration:  120\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7016829268292682\n",
            "Iteration:  130\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7140731707317073\n",
            "Iteration:  140\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7248536585365853\n",
            "Iteration:  150\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7354146341463415\n",
            "Iteration:  160\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7456585365853658\n",
            "Iteration:  170\n",
            "[1 2 2 ... 1 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7539268292682927\n",
            "Iteration:  180\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7616829268292683\n",
            "Iteration:  190\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7679756097560976\n",
            "Iteration:  200\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7742926829268293\n",
            "Iteration:  210\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7799756097560976\n",
            "Iteration:  220\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7855365853658537\n",
            "Iteration:  230\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7907073170731708\n",
            "Iteration:  240\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7956585365853659\n",
            "Iteration:  250\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.7997317073170732\n",
            "Iteration:  260\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8035365853658537\n",
            "Iteration:  270\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8070975609756098\n",
            "Iteration:  280\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8108048780487805\n",
            "Iteration:  290\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8137073170731707\n",
            "Iteration:  300\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8165853658536585\n",
            "Iteration:  310\n",
            "[1 2 2 ... 9 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8192195121951219\n",
            "Iteration:  320\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8220731707317073\n",
            "Iteration:  330\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8249756097560975\n",
            "Iteration:  340\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8274878048780487\n",
            "Iteration:  350\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8300243902439024\n",
            "Iteration:  360\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8320975609756097\n",
            "Iteration:  370\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.834170731707317\n",
            "Iteration:  380\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8358780487804878\n",
            "Iteration:  390\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8378292682926829\n",
            "Iteration:  400\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8394146341463414\n",
            "Iteration:  410\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8413414634146341\n",
            "Iteration:  420\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8430731707317073\n",
            "Iteration:  430\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8444146341463414\n",
            "Iteration:  440\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8458048780487805\n",
            "Iteration:  450\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8471951219512195\n",
            "Iteration:  460\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8482926829268292\n",
            "Iteration:  470\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8494390243902439\n",
            "Iteration:  480\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8507073170731707\n",
            "Iteration:  490\n",
            "[1 2 2 ... 7 2 8] [1 2 2 ... 7 2 8]\n",
            "0.8519024390243902\n",
            "Time gggggggpu taken:  88.89767026901245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xiffmU3DQY9n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}