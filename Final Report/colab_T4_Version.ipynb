{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sg86ybxfYCM",
        "outputId": "8ddca592-655e-4a98-a977-b5408e04aa52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9cgjep6z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9cgjep6z\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "# Load the extension that allows us to compile CUDA code in python notebooks\n",
        "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "GgUFIYVolT5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import os\n",
        "\n",
        "def download_mnist_dataset():\n",
        "    # 创建目录\n",
        "    os.makedirs(\"train_mnist/MNIST/raw\", exist_ok=True)\n",
        "    os.makedirs(\"test_mnist/MNIST/raw\", exist_ok=True)\n",
        "\n",
        "    # 下载训练数据\n",
        "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "    print(\"MNIST dataset downloaded successfully.\")\n",
        "\n",
        "# 调用函数下载数据集\n",
        "download_mnist_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ca_dytlrnY",
        "outputId": "dd6b9f4e-9082-45ff-ddc6-a8914d9c166f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST dataset downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-X3xtiKKRV6i",
        "outputId": "c66599b7-5c22-440b-d1dc-f0d03f7aa4a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "'''DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'''\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yg7P0ezLfcos"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"knn\" -n \"main.cu\"\n",
        "\n",
        "// Required header files / 所需的头文件\n",
        "#include <iostream>     // For input/output operations / 用于输入输出操作\n",
        "#include <fstream>      // For file operations / 用于文件操作\n",
        "#include <vector>       // For vector container / 用于向量容器\n",
        "#include <string>       // For string operations / 用于字符串操作\n",
        "#include <cstring>      // For C-style string operations / 用于C风格字符串操作\n",
        "#include <algorithm>    // For algorithms like max_element / 用于算法如max_element\n",
        "#include <cuda_runtime.h> // For CUDA operations / 用于CUDA操作\n",
        "#include <cfloat>\n",
        "\n",
        "// Constants definition / 常量定义\n",
        "#define THREADS 256        // Number of threads per block / 每个块的线程数\n",
        "#define IMAGESIZE 784      // Image size (28x28 = 784 pixels) / 图像大小 (28x28 = 784像素)\n",
        "#define TILE_WIDTH 32\n",
        "#define SHARED_MEM_SIZE (TILE_WIDTH * IMAGESIZE)\n",
        "#define max_samples = 1000\n",
        "\n",
        "// Function to handle big-endian to little-endian conversion\n",
        "// 处理大端序转小端序的函数\n",
        "uint32_t swap32(uint32_t val) {\n",
        "    val = ((val << 8) & 0xFF00FF00) | ((val >> 8) & 0xFF00FF);\n",
        "    return (val << 16) | (val >> 16);\n",
        "}\n",
        "\n",
        "// structure to store training/testing samples\n",
        "// 存储训练/测试样本的结构体\n",
        "struct TrainingSample {\n",
        "    int label;                  // The digit (0-9) / 数字标签 (0-9)\n",
        "    float image[IMAGESIZE];     // Normalized pixel values / 归一化的像素值\n",
        "};\n",
        "\n",
        "__global__ void bitonicSortStep(float* d_distances, int* d_labels, int j, int k, int num_samples) {\n",
        "    // 使用共享内存来减少全局内存访问\n",
        "    __shared__ float s_distances[1024];  // 设置为合适的大小\n",
        "    __shared__ int s_labels[1024];\n",
        "\n",
        "    const unsigned int tid = threadIdx.x;\n",
        "    const unsigned int bid = blockIdx.x;\n",
        "    const unsigned int gid = bid * blockDim.x + tid;\n",
        "    const unsigned int gridSize = gridDim.x * blockDim.x;\n",
        "\n",
        "    // 每个线程块处理多个元素\n",
        "    for (unsigned int i = gid; i < num_samples; i += gridSize) {\n",
        "        s_distances[tid] = d_distances[i];\n",
        "        s_labels[tid] = d_labels[i];\n",
        "        __syncthreads();\n",
        "\n",
        "        unsigned int ixj = i ^ j;\n",
        "\n",
        "        if (ixj > i && ixj < num_samples) {\n",
        "            float dist_i = s_distances[tid];\n",
        "            float dist_ixj = d_distances[ixj];\n",
        "            int label_i = s_labels[tid];\n",
        "            int label_ixj = d_labels[ixj];\n",
        "\n",
        "            bool swap = ((i & k) == 0) ? (dist_i > dist_ixj) : (dist_i < dist_ixj);\n",
        "\n",
        "            if (swap) {\n",
        "                s_distances[tid] = dist_ixj;\n",
        "                s_labels[tid] = label_ixj;\n",
        "                d_distances[ixj] = dist_i;\n",
        "                d_labels[ixj] = label_i;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        d_distances[i] = s_distances[tid];\n",
        "        d_labels[i] = s_labels[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "void bitonicSort(float* d_distances, int* d_labels, int num_samples) {\n",
        "    // 计算最近的2的幂\n",
        "    int pow2_size = 1;\n",
        "    while (pow2_size < num_samples) pow2_size <<= 1;\n",
        "    int padded_size = pow2_size;\n",
        "\n",
        "    // 一次性初始化填充数据\n",
        "    if (padded_size > num_samples) {\n",
        "        const float max_distance = FLT_MAX;\n",
        "        const int max_label = -1;\n",
        "\n",
        "        // 分配并初始化填充数据\n",
        "        float* h_pad_distances = new float[padded_size - num_samples];\n",
        "        int* h_pad_labels = new int[padded_size - num_samples];\n",
        "\n",
        "        for (int i = 0; i < padded_size - num_samples; ++i) {\n",
        "            h_pad_distances[i] = max_distance;\n",
        "            h_pad_labels[i] = max_label;\n",
        "        }\n",
        "\n",
        "        cudaMemcpy(d_distances + num_samples, h_pad_distances,\n",
        "                  (padded_size - num_samples) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_labels + num_samples, h_pad_labels,\n",
        "                  (padded_size - num_samples) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "        delete[] h_pad_distances;\n",
        "        delete[] h_pad_labels;\n",
        "    }\n",
        "\n",
        "    // 优化的网格配置\n",
        "    const int threadsPerBlock = 256;\n",
        "    const int numBlocks = (padded_size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // 使用循环展开来减少循环开销\n",
        "    #pragma unroll 4\n",
        "    for (int k = 2; k <= pow2_size; k <<= 1) {\n",
        "        #pragma unroll 4\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {\n",
        "            bitonicSortStep<<<numBlocks, threadsPerBlock>>>(\n",
        "                d_distances, d_labels, j, k, padded_size);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void computeEuclideanDistances(float* d_images, float* d_testImage,\n",
        "                                          float* d_distances, int* d_labels,\n",
        "                                          int* d_train_labels, int num_samples) {\n",
        "    __shared__ float shared_test[IMAGESIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int bid = blockIdx.x;\n",
        "    int idx = bid * blockDim.x + tid;\n",
        "\n",
        "    // 高效加载测试图像到共享内存\n",
        "    #pragma unroll\n",
        "    for (int i = 0; i < IMAGESIZE; i += blockDim.x) {\n",
        "        if (i + tid < IMAGESIZE) {\n",
        "            shared_test[i + tid] = d_testImage[i + tid];\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if (idx < num_samples) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        // 使用更高效的计算方式\n",
        "        #pragma unroll 32\n",
        "        for (int i = 0; i < IMAGESIZE; ++i) {\n",
        "            float diff = d_images[idx * IMAGESIZE + i] - shared_test[i];\n",
        "            sum += diff * diff;\n",
        "        }\n",
        "\n",
        "        d_distances[idx] = sqrtf(sum);\n",
        "        d_labels[idx] = d_train_labels[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// function to load MNIST dataset in IDX format\n",
        "// 加载IDX格式MNIST数据集的函数\n",
        "bool loadMNISTImages(const std::string& image_path, const std::string& label_path,\n",
        "                    std::vector<TrainingSample>& samples) {\n",
        "    // Open image file / 打开图像文件\n",
        "    std::ifstream image_file(image_path, std::ios::binary);\n",
        "    if (!image_file) {\n",
        "        std::cerr << \"Cannot open image file: \" << image_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Open label file / 打开标签文件\n",
        "    std::ifstream label_file(label_path, std::ios::binary);\n",
        "    if (!label_file) {\n",
        "        std::cerr << \"Cannot open label file: \" << label_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Read image file header / 读取图像文件头\n",
        "    uint32_t magic, num_items, num_rows, num_cols;\n",
        "    image_file.read(reinterpret_cast<char*>(&magic), sizeof(magic));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_items), sizeof(num_items));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_rows), sizeof(num_rows));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_cols), sizeof(num_cols));\n",
        "\n",
        "    // Convert from big-endian to host endian / 从大端序转换为主机字节序\n",
        "    magic = swap32(magic);\n",
        "    num_items = swap32(num_items);\n",
        "    num_rows = swap32(num_rows);\n",
        "    num_cols = swap32(num_cols);\n",
        "\n",
        "    // Verify image file format / 验证图像文件格式\n",
        "    if (magic != 0x803) {\n",
        "        std::cerr << \"Invalid image file format\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Read label file header / 读取标签文件头\n",
        "    uint32_t label_magic, num_labels;\n",
        "    label_file.read(reinterpret_cast<char*>(&label_magic), sizeof(label_magic));\n",
        "    label_file.read(reinterpret_cast<char*>(&num_labels), sizeof(num_labels));\n",
        "\n",
        "    // Convert label file header / 转换标签文件头\n",
        "    label_magic = swap32(label_magic);\n",
        "    num_labels = swap32(num_labels);\n",
        "\n",
        "    // Verify label file format / 验证标签文件格式\n",
        "    if (label_magic != 0x801) {\n",
        "        std::cerr << \"Invalid label file format\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Check consistency between images and labels / 检查图像和标签数量是否一致\n",
        "    if (num_items != num_labels) {\n",
        "        std::cerr << \"Number of images doesn't match number of labels\" << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Prepare storage / 准备存储空间\n",
        "    samples.resize(num_items);\n",
        "    std::vector<unsigned char> pixels(num_rows * num_cols);\n",
        "\n",
        "    // Read and process each sample / 读取并处理每个样本\n",
        "    for (uint32_t i = 0; i < num_items; ++i) {\n",
        "        // Read label / 读取标签\n",
        "        unsigned char label;\n",
        "        label_file.read(reinterpret_cast<char*>(&label), 1);\n",
        "        samples[i].label = static_cast<int>(label);\n",
        "\n",
        "        // Read image / 读取图像\n",
        "        image_file.read(reinterpret_cast<char*>(pixels.data()), pixels.size());\n",
        "\n",
        "        // Normalize pixel values to [0,1] / 将像素值归一化到[0,1]范围\n",
        "        for (size_t j = 0; j < pixels.size(); ++j) {\n",
        "            samples[i].image[j] = static_cast<float>(pixels[j]) / 255.0f;\n",
        "        }\n",
        "\n",
        "        // Show progress / 显示进度\n",
        "        if (i % 1000 == 0) {\n",
        "            std::cout << \"\\rLoading data: \" << (i * 100.0f / num_items) << \"%\" << std::flush;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"\\rLoading data: 100%\" << std::endl;\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Timing events\n",
        "    cudaEvent_t total_start, total_stop;\n",
        "    cudaEventCreate(&total_start);\n",
        "    cudaEventCreate(&total_stop);\n",
        "    cudaEventRecord(total_start);\n",
        "\n",
        "    cudaEvent_t load_start, load_stop;\n",
        "    cudaEventCreate(&load_start);\n",
        "    cudaEventCreate(&load_stop);\n",
        "    cudaEventRecord(load_start);\n",
        "\n",
        "    // Load data\n",
        "    std::vector<TrainingSample> train_samples;\n",
        "    std::vector<TrainingSample> test_samples;\n",
        "\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/train-images-idx3-ubyte\",\n",
        "                     \"./data/MNIST/raw/train-labels-idx1-ubyte\",\n",
        "                     train_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/t10k-images-idx3-ubyte\",\n",
        "                        \"./data/MNIST/raw/t10k-labels-idx1-ubyte\",\n",
        "                        test_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // 限制样本数量以适应 T4 内存\n",
        "    const int max_test_samples = 1000;\n",
        "    const int max_train_samples = max_test_samples * 10;\n",
        "\n",
        "    if (test_samples.size() > max_test_samples) {\n",
        "        test_samples.resize(max_test_samples);\n",
        "    }\n",
        "    if (train_samples.size() > max_train_samples) {\n",
        "        train_samples.resize(max_train_samples);\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(load_stop);\n",
        "    cudaEventSynchronize(load_stop);\n",
        "    float load_time;\n",
        "    cudaEventElapsedTime(&load_time, load_start, load_stop);\n",
        "\n",
        "    int num_trainsamples = train_samples.size();\n",
        "    int num_testsamples = test_samples.size();\n",
        "\n",
        "    std::cout << \"Training samples: \" << num_trainsamples << std::endl;\n",
        "    std::cout << \"Test samples: \" << num_testsamples << std::endl;\n",
        "\n",
        "    // Allocate host memory for training data\n",
        "    float* h_train_images = new float[num_trainsamples * IMAGESIZE];\n",
        "    int* h_train_labels = new int[num_trainsamples];\n",
        "\n",
        "    for (int i = 0; i < num_trainsamples; ++i) {\n",
        "        h_train_labels[i] = train_samples[i].label;\n",
        "        std::memcpy(&h_train_images[i * IMAGESIZE], train_samples[i].image, sizeof(float) * IMAGESIZE);\n",
        "    }\n",
        "\n",
        "    // Pre-allocate all GPU memory we'll need\n",
        "    float* d_train_images;\n",
        "    int* d_train_labels;\n",
        "    float* d_test_image;\n",
        "    float* d_distances;\n",
        "    int* d_sort_labels;\n",
        "\n",
        "    // Calculate padded size once\n",
        "    int pow2_size = 1;\n",
        "    while (pow2_size < num_trainsamples) pow2_size <<= 1;\n",
        "    int padded_size = pow2_size;\n",
        "\n",
        "    // Allocate all GPU memory at once\n",
        "    cudaMalloc(&d_train_images, num_trainsamples * IMAGESIZE * sizeof(float));\n",
        "    cudaMalloc(&d_train_labels, num_trainsamples * sizeof(int));\n",
        "    cudaMalloc(&d_test_image, IMAGESIZE * sizeof(float));\n",
        "    cudaMalloc(&d_distances, padded_size * sizeof(float));\n",
        "    cudaMalloc(&d_sort_labels, padded_size * sizeof(int));\n",
        "\n",
        "    // Copy training data to GPU\n",
        "    cudaMemcpy(d_train_images, h_train_images, num_trainsamples * IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_train_labels, h_train_labels, num_trainsamples * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Pre-allocate host memory for results\n",
        "    float* h_distances = new float[padded_size];\n",
        "    int* h_labels = new int[padded_size];\n",
        "\n",
        "    // Initialize padding arrays once\n",
        "    if (padded_size > num_trainsamples) {\n",
        "        float* h_pad_distances = new float[padded_size - num_trainsamples];\n",
        "        int* h_pad_labels = new int[padded_size - num_trainsamples];\n",
        "        for (int i = 0; i < padded_size - num_trainsamples; ++i) {\n",
        "            h_pad_distances[i] = FLT_MAX;\n",
        "            h_pad_labels[i] = -1;\n",
        "        }\n",
        "        cudaMemcpy(d_distances + num_trainsamples, h_pad_distances,\n",
        "                  (padded_size - num_trainsamples) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_sort_labels + num_trainsamples, h_pad_labels,\n",
        "                  (padded_size - num_trainsamples) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "        delete[] h_pad_distances;\n",
        "        delete[] h_pad_labels;\n",
        "    }\n",
        "\n",
        "    // Start prediction timing\n",
        "    cudaEvent_t predict_start, predict_stop;\n",
        "    cudaEventCreate(&predict_start);\n",
        "    cudaEventCreate(&predict_stop);\n",
        "    cudaEventRecord(predict_start);\n",
        "\n",
        "    // KNN parameters\n",
        "    int k = 10;\n",
        "    int correct_predictions = 0;\n",
        "\n",
        "    // Process each test sample\n",
        "    for (int t = 0; t < num_testsamples; ++t) {\n",
        "        int test_label = test_samples[t].label;\n",
        "\n",
        "        // Copy test image to GPU\n",
        "        cudaMemcpy(d_test_image, test_samples[t].image, IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "        int threadsPerBlock = TILE_WIDTH;\n",
        "        int blocksPerGrid = (num_trainsamples + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "        // Compute distances\n",
        "        computeEuclideanDistances<<<blocksPerGrid, threadsPerBlock>>>(\n",
        "            d_train_images, d_test_image, d_distances, d_sort_labels, d_train_labels, num_trainsamples\n",
        "        );\n",
        "\n",
        "        // Sort distances\n",
        "        bitonicSort(d_distances, d_sort_labels, num_trainsamples);\n",
        "\n",
        "        // Copy top k results\n",
        "        cudaMemcpy(h_distances, d_distances, k * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "        cudaMemcpy(h_labels, d_sort_labels, k * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // 标签选择逻辑\n",
        "        std::vector<float> labelCount(10, 0.0f);\n",
        "        for (int i = 0; i < k; ++i) {\n",
        "            float weight = 1.0f / (h_distances[i] + 1e-5);\n",
        "            labelCount[h_labels[i]] += weight;\n",
        "        }\n",
        "\n",
        "        int predictedLabel = std::distance(labelCount.begin(),\n",
        "            std::max_element(labelCount.begin(), labelCount.end()));\n",
        "\n",
        "        if (predictedLabel == test_label) {\n",
        "            correct_predictions++;\n",
        "        }\n",
        "\n",
        "        if (t % 100 == 0) {\n",
        "            std::cout << \"Processed \" << t << \" test samples\" << std::endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Record prediction time\n",
        "    cudaEventRecord(predict_stop);\n",
        "    cudaEventSynchronize(predict_stop);\n",
        "    float predict_time;\n",
        "    cudaEventElapsedTime(&predict_time, predict_start, predict_stop);\n",
        "\n",
        "    // Record total time\n",
        "    cudaEventRecord(total_stop);\n",
        "    cudaEventSynchronize(total_stop);\n",
        "    float total_time;\n",
        "    cudaEventElapsedTime(&total_time, total_start, total_stop);\n",
        "\n",
        "    // Calculate and display results\n",
        "    float accuracy = (float)correct_predictions / num_testsamples * 100.0f;\n",
        "\n",
        "    printf(\"Total test samples: %d\\n\", num_testsamples);\n",
        "    printf(\"Correct predictions: %d\\n\", correct_predictions);\n",
        "    printf(\"Accuracy: %.2f%%\\n\", accuracy);\n",
        "    printf(\"Total execution time: %.4f seconds\\n\", total_time/1000);\n",
        "    printf(\"Prediction time: %.4f seconds\\n\", predict_time/1000);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaEventDestroy(total_start);\n",
        "    cudaEventDestroy(total_stop);\n",
        "    cudaEventDestroy(load_start);\n",
        "    cudaEventDestroy(load_stop);\n",
        "    cudaEventDestroy(predict_start);\n",
        "    cudaEventDestroy(predict_stop);\n",
        "\n",
        "    // Free memory\n",
        "    delete[] h_train_images;\n",
        "    delete[] h_train_labels;\n",
        "    delete[] h_distances;\n",
        "    delete[] h_labels;\n",
        "    cudaFree(d_train_images);\n",
        "    cudaFree(d_train_labels);\n",
        "    cudaFree(d_test_image);\n",
        "    cudaFree(d_distances);\n",
        "    cudaFree(d_sort_labels);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC7tWV0Mh1hr",
        "outputId": "75b1ff19-c5b9-4ddd-d505-fe0d01b6ddd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rLoading data: 0%\rLoading data: 1.66667%\rLoading data: 3.33333%\rLoading data: 5%\rLoading data: 6.66667%\rLoading data: 8.33333%\rLoading data: 10%\rLoading data: 11.6667%\rLoading data: 13.3333%\rLoading data: 15%\rLoading data: 16.6667%\rLoading data: 18.3333%\rLoading data: 20%\rLoading data: 21.6667%\rLoading data: 23.3333%\rLoading data: 25%\rLoading data: 26.6667%\rLoading data: 28.3333%\rLoading data: 30%\rLoading data: 31.6667%\rLoading data: 33.3333%\rLoading data: 35%\rLoading data: 36.6667%\rLoading data: 38.3333%\rLoading data: 40%\rLoading data: 41.6667%\rLoading data: 43.3333%\rLoading data: 45%\rLoading data: 46.6667%\rLoading data: 48.3333%\rLoading data: 50%\rLoading data: 51.6667%\rLoading data: 53.3333%\rLoading data: 55%\rLoading data: 56.6667%\rLoading data: 58.3333%\rLoading data: 60%\rLoading data: 61.6667%\rLoading data: 63.3333%\rLoading data: 65%\rLoading data: 66.6667%\rLoading data: 68.3333%\rLoading data: 70%\rLoading data: 71.6667%\rLoading data: 73.3333%\rLoading data: 75%\rLoading data: 76.6667%\rLoading data: 78.3333%\rLoading data: 80%\rLoading data: 81.6667%\rLoading data: 83.3333%\rLoading data: 85%\rLoading data: 86.6667%\rLoading data: 88.3333%\rLoading data: 90%\rLoading data: 91.6667%\rLoading data: 93.3333%\rLoading data: 95%\rLoading data: 96.6667%\rLoading data: 98.3333%\rLoading data: 100%\n",
            "\rLoading data: 0%\rLoading data: 10%\rLoading data: 20%\rLoading data: 30%\rLoading data: 40%\rLoading data: 50%\rLoading data: 60%\rLoading data: 70%\rLoading data: 80%\rLoading data: 90%\rLoading data: 100%\n",
            "Training samples: 10000\n",
            "Test samples: 1000\n",
            "Processed 0 test samples\n",
            "Processed 100 test samples\n",
            "Processed 200 test samples\n",
            "Processed 300 test samples\n",
            "Processed 400 test samples\n",
            "Processed 500 test samples\n",
            "Processed 600 test samples\n",
            "Processed 700 test samples\n",
            "Processed 800 test samples\n",
            "Processed 900 test samples\n",
            "Total test samples: 1000\n",
            "Correct predictions: 477\n",
            "Accuracy: 47.70%\n",
            "Total execution time: 0.8644 seconds\n",
            "Prediction time: 0.6952 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cuda_group_run --group \"knn\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}